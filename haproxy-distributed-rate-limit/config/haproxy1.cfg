global 
    localpeer balancer01

# Task limit all requests to 400 per second for all IP addresses
defaults
    mode http
    timeout client 10s
    timeout connect 5s
    timeout server 10s 
    timeout http-request 10s

frontend frontend
    bind :8080
    default_backend backend
    # stick-table type integer size 1 expire 1s store http_req_rate(1s)
    # stick-table type integer size 1 expire 1m store http_req_rate(1m)
    # Use peers to store the rate limit
    # Multiple load balancers
    http-request track-sc0 always_true table sample_peers/balancer01
    http-request set-var(req.rps01a) sc0_http_req_rate(sample_peers/balancer01)
    http-request set-var(req.rps02a) sc0_http_req_rate(sample_peers/balancer02)
    http-request set-var(req.rps) var(req.rps01a),add(req.rps02a)
    # New syntax for sticky counter sc0_http_req_rate
    # http-request set-var(req.rps) sc0_http_req_rate()
    # Access control list to limit requests per second
    acl rps_over_limit var(req.rps) -m int gt 400
    use_backend be_error_429 if rps_over_limit
    # http-request deny if { sc0_http_req_rate() gt 400 }

backend backend
    server nginx1 nginx-1:80
    server nginx2 nginx-2:80
    server nginx3 nginx-3:80

backend be_error_429
    errorfile 429 /usr/local/etc/haproxy/errors/429.http
    http-request deny deny_status 429

peers sample_peers
    bind :10000
    server balancer01
    server balancer02 haproxy-2:10000
    table balancer01 type integer size 1 expire 1m store http_req_rate(1m)
    table balancer02 type integer size 1 expire 1m store http_req_rate(1m)
